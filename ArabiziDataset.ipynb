{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ArabiziDataset.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"U-K_Fj0NHbiB","colab_type":"code","outputId":"78bb081a-f071-433d-8efe-7d9856c36f69","executionInfo":{"status":"ok","timestamp":1587645870338,"user_tz":-180,"elapsed":2693,"user":{"displayName":"Yazan Hajj Diab","photoUrl":"","userId":"17261519561235683636"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["import pandas as pd\n","import re\n","import random\n","def clean_text(tweet):\n","    #remove emoji\n","    emoji = re.compile(\"[\"\n","                        u'\\U0001F600-\\U0001F64F'  # emoticons\n","                        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n","                        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n","                        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n","                        u'\\U00002702-\\U000027B0'\n","                        u'\\U000024C2-\\U0001F251'\n","                        \"]+\", flags=re.UNICODE)\n","    tweet = emoji.sub(r'', tweet)\n","\n","    #remove punctuation\n","    punctuation = '''!\\(\\)-\\[]\\{};:'\"\\,<>./?@#$%^&*_~=+…''' + u'\\u060C' + u'\\u061B' + u'\\u061F'\n","    for c in tweet:\n","        if c in punctuation:\n","            tweet = tweet.replace(c, '')\n","\n","    #remove laughter\n","    laughter = re.compile(r'\\b(ه|خ)\\1{2,}\\b')\n","    tweet = laughter.sub('', tweet)\n","\n","    #remove nonsense\n","    laughter = re.compile(r'\\b(.)\\1{2,}\\b')\n","    tweet = laughter.sub(r'', tweet)\n","\n","    #normalize elongated words\n","    repeated_characters = re.compile(r'(.)\\1{2,}')\n","    tweet = repeated_characters.sub(r'\\1', tweet)\n","\n","    return tweet\n","\n","def ArabicToArabizi(tweet):\n","    arabicLetterList = ['ض','ص','ث','ق' ,'ف' ,\n","                                  'غ' ,'ع' ,'ه','خ' ,'ح' ,\n","                                  'ج' ,'د' ,'ش' ,'س' ,'ي' ,\n","                                  'ن','ت' ,'ا' ,'ل','ب',\n","                                  'ء','ئ','ط' ,'ك','م',\n","                                  'ؤ','ر','لا','ى','ة',\n","                                  'و','ز' ,'ظ','لأ','أ' ,\n","                             'إ', 'آ', ' ','ذ']\n","    \n","    arabiziMappingList = [['d'],['s'],['th'],[ '2'],['f'],\n","                      ['8'], [ '3'], ['h'], ['5'],['7'],\n","                      ['j'], ['d'], ['sh'], ['s'], ['y'],\n","                      ['n'], ['t'], ['a'], ['l'], ['b'],\n","                      ['2'],['2'], ['t'], ['k'], ['m'],\n","                      ['o2'], ['r'], ['la'], ['a'], ['a'],\n","                      ['o'], ['z'], ['z'], ['la2'], ['2'],\n","                      ['2'],['2'], [' '], ['z']]\n","    arabiziSentence =''\n","    arabicToArabiziMapping = dict()\n","    for x in range(0, len(arabicLetterList)):\n","        arabicToArabiziMapping[arabicLetterList[x]] = arabiziMappingList[x] \n","    for x in range(0, len(tweet)):\n","        if tweet[x] in arabicToArabiziMapping.keys():\n","            if tweet[x] ==  'و':\n","                if x == 0:\n","                    arabiziSentence = arabiziSentence + 'w'\n","                elif tweet[x-1] ==' ':\n","                    arabiziSentence = arabiziSentence + 'w'\n","                else:\n","                    arabiziSentence = arabiziSentence + 'o'\n","            else :\n","                arabiziSentence = arabiziSentence + arabicToArabiziMapping[tweet[x]][random.randint(0,\n","                                                                 len(arabicToArabiziMapping[tweet[x]])-1)]\n","    arabiziSentence = arabiziSentence.replace( 'alozyr', 'alwazer')\n","    arabiziSentence = arabiziSentence.replace( 'hza', 'hayda')\n","    arabiziSentence = arabiziSentence.replace( 'hzh', 'hayde')\n","    arabiziSentence = arabiziSentence.replace( ' lao ', ' law ')\n","    arabiziSentence = arabiziSentence.replace( ' ho ', ' huwe ')\n","    arabiziSentence = arabiziSentence.replace( 'jbran ', ' gebran ')\n","    arabiziSentence = arabiziSentence.replace( 'qtr ', ' qatar ')\n","    arabiziSentence = arabiziSentence.replace( 'wlyd ', ' walid ')\n","    arabiziSentence = arabiziSentence.replace( 'al7ryry ', ' al hariri ')\n","    return arabiziSentence\n","\n","url = 'https://raw.githubusercontent.com/Hala-Mulki/L-HSAB-First-Arabic-Levantine-HateSpeech-Dataset/master/Dataset/L-HSAB'\n","lhsab = pd.read_csv(url, sep='\\t')\n","\n","#print(type(lhsab))\n","\n","newArabiziDataset = dict()\n","arabiziTweets = list()\n","arabiziClasses = list()\n","numberOfTweets = len(lhsab['Tweet'].value_counts())\n","#print(numberOfTweets)\n","count = 0\n","for tweet in lhsab['Tweet']:\n","    newTweet = ArabicToArabizi(clean_text(tweet))\n","    arabiziTweets.append(newTweet)\n","    arabiziClasses.append(lhsab['Class'][count])\n","    count = count + 1\n","\n","newArabiziDataset['Tweet'] = arabiziTweets\n","newArabiziDataset['Class'] = arabiziClasses\n","newDataSet = pd.DataFrame(newArabiziDataset,columns= ['Tweet', 'Class'])\n","\n","print(newDataSet)    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["                                                  Tweet    Class\n","0     alwazer  gebran basyl taj rask ya jrban mmno3 ...  abusive\n","1     sdy2y ant abn jam3h all3bh akbr mn da3sh all3b...   normal\n","2     w msl7a lbnan tbd2 bast5raj alnft w al8az lo2f...   normal\n","3                      walid jnblat katb al7kma ya 2zr   abusive\n","4     sho btlb2lk klma 5nzyr btjy mfslh 3la 2yask ws...  abusive\n","...                                                 ...      ...\n","5841                            2myr almlyshya msh 5a2n   normal\n","5842                               sd2t ynasbk jda jda    normal\n","5843                           lb5lyny 7b basyl sh8ltyn   normal\n","5844  lysh tyos al2mart wals3odya m3 alsoryyn walymn...     hate\n","5845  msh dfa3a 3n  gebran basyl bs kan lazm t7t alm...   normal\n","\n","[5846 rows x 2 columns]\n"],"name":"stdout"}]}]}